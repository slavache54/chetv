import asyncio
import aiohttp
import re
import os
import sys
from collections import defaultdict

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
SOURCES_FILE = 'sources.txt'
OUTPUT_FILE = 'master_playlist.m3u'

# –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤
HEADERS = {
    'User-Agent': 'VLC/3.0.18 LibVLC/3.0.18',
    'Accept': '*/*'
}

def load_sources():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ —Ñ–∞–π–ª–∞ —Ñ–æ—Ä–º–∞—Ç–∞ '–ù–∞–∑–≤–∞–Ω–∏–µ,URL'."""
    sources = []
    if not os.path.exists(SOURCES_FILE):
        return sources
    with open(SOURCES_FILE, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            parts = line.split(',', 1)
            if len(parts) == 2:
                name, url = parts[0].strip(), parts[1].strip()
                sources.append({'name': name, 'url': url})
            else:
                name = f"–ò—Å—Ç–æ—á–Ω–∏–∫ {i + 1}"
                url = line
                sources.append({'name': name, 'url': url})
    return sources

def parse_m3u_content(content):
    """–ü—Ä–æ—Å—Ç–æ –ø–∞—Ä—Å–∏—Ç M3U, –∏–∑–≤–ª–µ–∫–∞—è –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ URL –∫–∞–Ω–∞–ª–∞."""
    channels = []
    # –ü—Ä–æ—Å—Ç–æ–π regex, –∫–æ—Ç–æ—Ä—ã–π –∏—â–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –∏ URL –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ
    pattern = re.compile(r'#EXTINF:-1.*?,([^\n]*)\n(https?://[^\n]*)')
    matches = pattern.findall(content)
    for name, url in matches:
        clean_name = name.strip()
        if clean_name and url:
            channels.append({'name': clean_name, 'url': url.strip()})
    return channels

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤."""
    print("--- –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤ (–ë–ï–ó –ü–†–û–í–ï–†–ö–ò) ---")
    
    sources = load_sources()
    if not sources:
        print(f"[–û–®–ò–ë–ö–ê] –§–∞–π–ª '{SOURCES_FILE}' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç.")
        return
        
    print(f"–ù–∞–π–¥–µ–Ω–æ {len(sources)} –ø–ª–µ–π–ª–∏—Å—Ç–æ–≤-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.")

    final_header = '#EXTM3U'
    epg_found = False
    # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤, —Å–≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ –∏–º–µ–Ω–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
    categorized_channels = defaultdict(list)
    total_channels_found = 0

    async with aiohttp.ClientSession(headers=HEADERS) as session:
        for source in sources:
            source_name = source['name']
            url = source['url']
            try:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∫–∞: {source_name} ({url})")
                async with session.get(url, timeout=15) as response:
                    response.raise_for_status()
                    content = await response.text()

                    if not epg_found:
                        for line in content.splitlines():
                            if line.strip().startswith("#EXTM3U") and 'url-tvg' in line:
                                final_header = line.strip()
                                epg_found = True
                                print(f"    -> –ù–∞–π–¥–µ–Ω –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å EPG.")
                                break
                    
                    parsed_channels = parse_m3u_content(content)
                    
                    # –ü—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –∫–∞–Ω–∞–ª—ã –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Å –∏–º–µ–Ω–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                    categorized_channels[source_name].extend(parsed_channels)
                    
                    count = len(parsed_channels)
                    total_channels_found += count
                    print(f"    -> –ù–∞–π–¥–µ–Ω–æ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–æ {count} –∫–∞–Ω–∞–ª–æ–≤.")

            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                print(f"    -> –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–ª–µ–π–ª–∏—Å—Ç: {e}")

    print("\n–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–∏–º–µ–Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤) –ø–æ –∞–ª—Ñ–∞–≤–∏—Ç—É
    sorted_categories = sorted(categorized_channels.keys())
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        f.write(f"{final_header}\n")
        for category in sorted_categories:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–Ω–∞–ª—ã –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ –∏–º–µ–Ω–∏
            channels_in_category = sorted(categorized_channels[category], key=lambda x: x['name'])
            for channel in channels_in_category:
                f.write(f'#EXTINF:-1 group-title="{category}",{channel["name"]}\n')
                f.write(f'{channel["url"]}\n')
            
    print("\n--- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã ---")
    print(f"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –ø–ª–µ–π–ª–∏—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {OUTPUT_FILE}")
    print(f"üìä –í—Å–µ–≥–æ –∫–∞–Ω–∞–ª–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø–ª–µ–π–ª–∏—Å—Ç: {total_channels_found}")
    print("\n–í–Ω–∏–º–∞–Ω–∏–µ: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –∏ —É–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –±—ã–ª–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

if __name__ == '__main__':
    asyncio.run(main())
